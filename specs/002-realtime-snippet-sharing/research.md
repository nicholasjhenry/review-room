# Technical Research: Real-Time Code Snippet Sharing System

**Date**: 2025-10-21
**Feature**: Real-Time Code Snippet Sharing System
**Purpose**: Resolve technical unknowns identified in plan.md Technical Context

## Research Summary

This document resolves 5 key technical decisions needed for implementation:

1. Syntax highlighting approach
2. Real-time cursor/selection state management
3. Snippet ID generation strategy
4. Language detection approach
5. Public gallery pagination/search strategy

---

## Decision 1: Syntax Highlighting

### Decision
**Client-side syntax highlighting using highlight.js**

### Rationale

**Why Client-Side:**
- Server-side highlighting (Elixir's `makeup` library) would require:
  - Generating highlighted HTML on server for every snippet view
  - Re-sending full highlighted content on every cursor update (inefficient)
  - Limited language support (makeup focuses on BEAM languages)

- Client-side highlighting:
  - Processes code once in browser, no server resources per view
  - Works seamlessly with LiveView (code sent as plain text, highlighted on mount)
  - Better real-time performance (no server round-trip for highlighting)
  - Broader language ecosystem (JavaScript libraries support 100+ languages)

**Why highlight.js:**
- **Language support**: 190+ languages out of box (exceeds 20+ requirement)
- **Bundle size**: ~80KB minified with common languages subset (acceptable)
- **Zero dependencies**: Pure JavaScript, no build system requirements
- **Auto-detection**: Built-in language detection (bonus feature)
- **Phoenix compatibility**: Works perfectly with LiveView hooks
- **Battle-tested**: Used by GitHub, Stack Overflow, MDN
- **MIT license**: No licensing concerns

### Alternatives Considered

**Prism.js:**
- Similar features to highlight.js
- Slightly more modular (can reduce bundle size)
- Less popular in Phoenix ecosystem
- **Rejected**: highlight.js has better auto-detection and larger community

**Monaco Editor (VS Code component):**
- Full code editor with IntelliSense, themes, etc.
- **Much heavier**: ~5MB bundle size
- Overkill for read-only viewing use case
- **Rejected**: Too heavy for snippet viewing (not editing)

**CodeMirror:**
- Powerful editor library (good for editing)
- ~500KB bundle size
- More complex integration
- **Rejected**: Optimized for editing, we need viewing + cursor overlay

**Server-side (Elixir makeup):**
- Native Elixir library
- Limited language support (~10 languages)
- Requires server processing per snippet view
- **Rejected**: Limited languages, inefficient for real-time collaboration

### Implementation Approach

```javascript
// assets/js/hooks/syntax_highlight.js
export const SyntaxHighlight = {
  mounted() {
    this.highlight();
  },
  updated() {
    this.highlight();
  },
  highlight() {
    const codeBlock = this.el.querySelector('code');
    if (codeBlock) {
      hljs.highlightElement(codeBlock);
    }
  }
};
```

```heex
<!-- In LiveView template -->
<div id="code-container" phx-hook="SyntaxHighlight" phx-update="ignore">
  <pre><code class="language-{@snippet.language}">{@snippet.code}</code></pre>
</div>
```

**Note**: Use `phx-update="ignore"` on the code container since highlight.js manages its own DOM (per Phoenix guidelines).

---

## Decision 2: Real-Time Cursor/Selection State Management

### Decision
**Phoenix Tracker with LiveView assigns for local state**

### Rationale

Phoenix Tracker is purpose-built for distributed presence tracking with these advantages:

**Scalability:**
- Designed for distributed Elixir clusters
- Handles 50+ users per snippet easily (tested in production apps at 1000+ users)
- CRDT-based conflict resolution (automatic consistency across nodes)
- Built-in heartbeat mechanism (detects disconnections within configurable timeout)

**Latency:**
- PubSub broadcasts are <50ms on same server
- Network latency dominant factor (<200ms achievable on reasonable connections)
- No database round-trips for presence updates

**Memory Efficiency:**
- Tracks process metadata (PID, user info) without database writes
- Automatic cleanup when processes die
- Per-snippet isolation (only subscribers receive updates)

**Phoenix Integration:**
- Native Phoenix library (`Phoenix.Tracker`)
- Works seamlessly with LiveView lifecycle
- Standard pattern in Phoenix ecosystem (used by Phoenix Presence)

### Alternatives Considered

**LiveView assigns only (no Tracker):**
- Store all cursors in socket assigns: `@cursors = %{user_id => position}`
- Broadcast via PubSub on each cursor move
- **Rejected**: No automatic disconnect detection, manual cleanup required, doesn't scale to distributed nodes

**ETS tables:**
- Shared memory across processes on single node
- Fast reads/writes (<1Î¼s)
- **Rejected**: Not distributed (doesn't work across nodes), manual cleanup, reinventing Phoenix Tracker

**LiveView streams:**
- Use `stream/3` for cursor collection
- **Rejected**: Streams are for append/delete collections, not real-time position updates (inefficient DOM updates)

### Implementation Pattern

```elixir
# lib/review_room/snippets/presence_tracker.ex
defmodule ReviewRoom.Snippets.PresenceTracker do
  use Phoenix.Tracker

  def start_link(opts) do
    opts = Keyword.merge([name: __MODULE__], opts)
    Phoenix.Tracker.start_link(__MODULE__, opts, opts)
  end

  def init(opts) do
    server = Keyword.fetch!(opts, :pubsub_server)
    {:ok, %{pubsub_server: server, node_name: Phoenix.PubSub.node_name(server)}}
  end

  def handle_diff(diff, state) do
    # Broadcast presence changes via PubSub
    for {topic, {joins, leaves}} <- diff do
      Phoenix.PubSub.broadcast(state.pubsub_server, topic,
        {:presence_diff, %{joins: joins, leaves: leaves}})
    end
    {:ok, state}
  end

  # Track user joining a snippet
  def track_user(snippet_id, user_id, user_meta) do
    Phoenix.Tracker.track(__MODULE__, self(), "snippet:#{snippet_id}", user_id, user_meta)
  end

  # Update cursor position
  def update_cursor(snippet_id, user_id, cursor_meta) do
    Phoenix.Tracker.update(__MODULE__, self(), "snippet:#{snippet_id}", user_id, cursor_meta)
  end
end
```

```elixir
# In LiveView
def mount(%{"id" => snippet_id}, _session, socket) do
  topic = "snippet:#{snippet_id}"
  Phoenix.PubSub.subscribe(ReviewRoom.PubSub, topic)

  # Track this user's presence
  user_id = get_user_id(socket)
  PresenceTracker.track_user(snippet_id, user_id, %{
    cursor: nil,
    selection: nil,
    joined_at: System.system_time(:second)
  })

  {:ok, assign(socket, snippet_id: snippet_id, presences: %{})}
end

def handle_event("cursor_moved", %{"line" => line, "column" => col}, socket) do
  user_id = get_user_id(socket)
  PresenceTracker.update_cursor(socket.assigns.snippet_id, user_id, %{
    cursor: %{line: line, column: col},
    selection: nil
  })
  {:noreply, socket}
end

def handle_info({:presence_diff, diff}, socket) do
  presences = merge_presence_diff(socket.assigns.presences, diff)
  {:noreply, assign(socket, presences: presences)}
end
```

**Latency characteristics**:
- PubSub broadcast: <10ms local, <100ms cross-region
- LiveView update: <50ms to render
- **Total**: <150ms well within 200ms requirement

---

## Decision 3: Snippet ID Generation

### Decision
**Short hash using nanoid (8-character alphanumeric)**

### Rationale

**User Experience:**
- Short, shareable URLs: `example.com/s/aB3dE5fG` (16 chars total path)
- Easy to read/type compared to UUID: `example.com/s/550e8400-e29b-41d4-a716-446655440000`
- Professional appearance (similar to Pastebin, GitHub Gists)

**Collision Resistance:**
- 8-character nanoid with 64-char alphabet: 64^8 = 281 trillion combinations
- At 1000 snippets/day: ~770 million years until 1% collision probability
- Far exceeds realistic scale requirements

**Ecto Integration:**
- Store as `:string` field (not `:binary_id`)
- Generate in changeset before insert
- Database unique constraint for safety

**Performance:**
- Simple string comparison (faster than UUID binary comparison)
- Indexable with standard B-tree index
- No encoding/decoding overhead in URLs

### Alternatives Considered

**UUID (Ecto :binary_id):**
- Phoenix default for `--binary-id` apps
- Guaranteed uniqueness
- **Rejected**: Long URLs (36 chars), poor user experience for sharing

**Base62 encoded auto-increment:**
- Very short IDs (e.g., "a1", "b2")
- Predictable/sequential
- **Rejected**: Reveals creation order (security concern), enables scraping

**Hashids:**
- Reversible encoding of integers
- Still reveals some information
- **Rejected**: Nanoid is simpler and more secure (random, not reversible)

**Custom slug (readable words):**
- Human-readable: "happy-blue-elephant"
- Longer URLs
- **Rejected**: Requires uniqueness checks, collision handling, not professional for code snippets

### Ecto Configuration

```elixir
# mix.exs - add dependency
{:nanoid, "~> 2.0"}

# lib/review_room/snippets/snippet.ex
defmodule ReviewRoom.Snippets.Snippet do
  use Ecto.Schema
  import Ecto.Changeset

  @primary_key {:id, :string, autogenerate: false}
  schema "snippets" do
    field :code, :string
    field :title, :string
    field :description, :string
    field :language, :string
    field :visibility, Ecto.Enum, values: [:public, :private], default: :private
    belongs_to :user, ReviewRoom.Accounts.User, type: :binary_id

    timestamps()
  end

  def changeset(snippet, attrs) do
    snippet
    |> cast(attrs, [:code, :title, :description, :language, :visibility, :user_id])
    |> validate_required([:code])
    |> generate_id()
    |> unique_constraint(:id)
  end

  defp generate_id(changeset) do
    case get_field(changeset, :id) do
      nil -> put_change(changeset, :id, Nanoid.generate(8))
      _id -> changeset
    end
  end
end
```

**Migration:**
```elixir
create table(:snippets, primary_key: false) do
  add :id, :string, primary_key: true
  add :code, :text, null: false
  # ... other fields
end

create unique_index(:snippets, [:id])
```

---

## Decision 4: Language Detection

### Decision
**Manual language selection (required) with simple file extension fallback (optional enhancement)**

### Rationale

**Simplicity:**
- No external dependencies or ML models
- Zero latency (no API calls or processing)
- Deterministic behavior (users know what they selected)
- Aligns with Constitution Principle III (simple, explicit over magic)

**Accuracy:**
- User knows the language better than any heuristic (100% accuracy when user specifies)
- Avoids misdetection errors (e.g., C vs C++, JavaScript vs TypeScript)
- Better UX than auto-detect + manual correction

**highlight.js Integration:**
- highlight.js has built-in auto-detection as fallback
- Can enable as progressive enhancement without Elixir dependency
- Works client-side (no server processing)

### Alternatives Considered

**Elixir language detection library:**
- Research shows no mature, maintained libraries on Hex.pm
- Would need to evaluate code content (CPU intensive)
- **Rejected**: Adds complexity, no clear benefit over user selection

**External APIs (GitHub Linguist):**
- GitHub's language detection (used in repos)
- Requires HTTP API calls (latency, rate limits, dependency)
- **Rejected**: External dependency, added latency, unnecessary for user-created snippets

**Simple heuristics (keyword detection):**
- Scan for language-specific keywords (e.g., "def" â Python/Ruby)
- Unreliable (many languages share keywords)
- **Rejected**: Low accuracy, not worth complexity

**highlight.js auto-detection (client-side):**
- Built-in feature of highlight.js
- Runs in browser (no server cost)
- **Accepted as fallback**: Use when user doesn't specify language

### Fallback Strategy

**Primary**: User selects language from dropdown (20+ common languages)

**Fallback**: If user skips language selection:
1. Store `language: nil` in database
2. Render with `<code>` (no language class)
3. highlight.js attempts auto-detection on client
4. If detection fails, display as plain text (still readable)

**Implementation:**
```elixir
# In changeset
def changeset(snippet, attrs) do
  snippet
  |> cast(attrs, [:code, :language, ...])
  |> validate_required([:code])
  |> validate_inclusion(:language, supported_languages(), message: "is not supported")
end

defp supported_languages do
  [
    "elixir", "javascript", "typescript", "python", "ruby", "go",
    "rust", "java", "kotlin", "swift", "c", "cpp", "csharp",
    "php", "sql", "html", "css", "json", "yaml", "markdown",
    "shell", "dockerfile", nil  # nil = auto-detect
  ]
end
```

**Template:**
```heex
<pre><code class={language_class(@snippet.language)}>
  {@snippet.code}
</code></pre>

defp language_class(nil), do: ""  # Auto-detect
defp language_class(lang), do: "language-#{lang}"
```

---

## Decision 5: Public Gallery Pagination/Search Strategy

### Decision
**PostgreSQL ILIKE queries with cursor-based pagination, LiveView streams for rendering**

### Rationale

**MVP Simplicity:**
- PostgreSQL ILIKE handles simple keyword search (no external dependencies)
- Standard WHERE clauses for filtering (language, visibility)
- Cursor-based pagination works with LiveView streams
- Can migrate to full-text search later if needed (non-breaking)

**Performance:**
- ILIKE with indexes handles 100k+ snippets reasonably (<100ms queries)
- Cursor pagination avoids OFFSET performance issues
- Indexed columns (language, visibility, inserted_at) for fast filtering

**LiveView Integration:**
- Streams with `reset: true` for filter/search changes
- Infinite scroll pattern (append new pages to stream)
- Efficient DOM updates (only new snippets rendered)

**Scalability Path:**
- Start with ILIKE for MVP
- Add PostgreSQL full-text search (tsvector/tsquery) at 10k+ snippets
- Migrate to Elasticsearch only if needed (100k+ snippets with complex search)

### Alternatives Considered

**PostgreSQL full-text search:**
- Better performance for large text searches
- Requires tsvector columns, GIN indexes, migration
- **Rejected for MVP**: Premature optimization, ILIKE sufficient initially

**Elasticsearch/Meilisearch:**
- Best search performance and features
- Requires external service, deployment complexity, data sync
- **Rejected**: Over-engineered for MVP, can add later

**Offset-based pagination:**
- Simpler implementation (`LIMIT/OFFSET`)
- Performance degrades at large offsets (slow queries at page 100+)
- **Rejected**: Cursor-based is better practice, works with streams

### Index Strategy

```elixir
# Migration
create table(:snippets) do
  # ... fields
end

# Indexes for common queries
create index(:snippets, [:visibility])           # Filter public/private
create index(:snippets, [:language])             # Filter by language
create index(:snippets, [:inserted_at])          # Sort by recency
create index(:snippets, [:user_id])              # User's snippets
create index(:snippets, [:visibility, :inserted_at])  # Composite for gallery

# For search (upgrade path)
# create index(:snippets, ["to_tsvector('english', title || ' ' || description)"],
#              using: :gin, name: :snippets_search_idx)
```

### LiveView Pattern

```elixir
# lib/review_room_web/live/snippet_live/index.ex
def mount(_params, _session, socket) do
  if connected?(socket) do
    # Load first page
    snippets = list_public_snippets(limit: 20)
    {:ok, stream(socket, :snippets, snippets)}
  else
    {:ok, stream(socket, :snippets, [])}
  end
end

def handle_event("load_more", %{"cursor" => cursor}, socket) do
  snippets = list_public_snippets(cursor: cursor, limit: 20)
  {:noreply, stream(socket, :snippets, snippets)}  # Append to stream
end

def handle_event("filter", %{"language" => lang}, socket) do
  snippets = list_public_snippets(language: lang, limit: 20)
  {:noreply, stream(socket, :snippets, snippets, reset: true)}  # Reset stream
end

def handle_event("search", %{"query" => query}, socket) do
  snippets = search_snippets(query, limit: 20)
  {:noreply, stream(socket, :snippets, snippets, reset: true)}
end

# Context function
def search_snippets(query, opts \\ []) do
  limit = Keyword.get(opts, :limit, 20)

  Snippet
  |> where([s], s.visibility == :public)
  |> where([s], ilike(s.title, ^"%#{query}%") or ilike(s.description, ^"%#{query}%"))
  |> order_by([s], desc: s.inserted_at)
  |> limit(^limit)
  |> Repo.all()
end
```

**Template:**
```heex
<div id="snippets" phx-update="stream">
  <div :for={{id, snippet} <- @streams.snippets} id={id}>
    <!-- Snippet card -->
  </div>
</div>

<div phx-click="load_more" phx-value-cursor={@cursor}>
  Load More
</div>
```

**Query performance**: ILIKE with index on 100k rows: ~50-100ms (acceptable for MVP)

---

## Research Complete

All technical unknowns from `plan.md` have been resolved:

â **Syntax highlighting**: Client-side with highlight.js
â **Cursor state management**: Phoenix Tracker + LiveView assigns
â **Snippet IDs**: 8-character nanoid
â **Language detection**: Manual selection with auto-detect fallback
â **Gallery pagination**: PostgreSQL ILIKE + cursor pagination + streams

**Next Phase**: Data model design (Phase 1)
